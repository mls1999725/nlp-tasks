{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c-lstm-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJs6iXHN4Raa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils as utils\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6v59p3X4yqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.01\n",
        "init_weight_decay = 0 \n",
        "epochs = 200 \n",
        "batch_size = 16\n",
        "def train_epoch(train_iter, dev_iter, test_iter, model):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = init_weight_decay)\n",
        "  steps = 0\n",
        "  model_count = 0\n",
        "  model.train()\n",
        "  for epoch in range(1, epochs+1):\n",
        "    steps = 0\n",
        "    print(\"\\n ## The {} Epoch, All {} Epoch ! ##\".format(epoch, epochs))\n",
        "    for batch in train_iter:\n",
        "      feature, target = batch.text, batch.label\n",
        "      target = autograd.Variable(target)\n",
        "      optimizer.zero_grad()\n",
        "      logit = model(feature)\n",
        "      #print(target.size(), logit.size())\n",
        "      loss = F.cross_entropy(logit, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      steps += 1\n",
        "      if steps % 4 == 0:\n",
        "        print(\"hahaha\", torch.max(logit, 1)[1])\n",
        "        corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "        accuracy = float(corrects) / batch_size * 100.0\n",
        "        print(accuracy)\n",
        "        \n",
        "      if steps % 4 == 0:\n",
        "        print(\"\\n Dev accuracy: \", end=\"\")\n",
        "        eval(dev_iter, model, epoch)\n",
        "        #print(\"Test accuract: \", end=\"\")\n",
        "    print(steps)\n",
        "        \n",
        "def eval(data_iter, model, epoch, test=False):\n",
        "  model.eval()\n",
        "  corrects, avg_loss = 0, 0\n",
        "  for batch in data_iter:\n",
        "    feature, target = batch.text, batch.label\n",
        "    logit = model(feature)\n",
        "    loss = F.cross_entropy(logit, target)\n",
        "    avg_loss += loss.item()\n",
        "    \n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "  \n",
        "  size = len(data_iter.dataset)\n",
        "  avg_loss = avg_loss / size\n",
        "  accuracy = float(corrects) / size * 100.0\n",
        "  \n",
        "  print('Evaluation - loss: {:.6f} acc: {:.4f}%({}/{})'.format(avg_loss, accuracy, corrects, size))\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it5YgLUy_IT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Neural Network: CNN_LSTM\n",
        "    Detail: the input crosss cnn model and LSTM model independly, then the result of both concat\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, lstm_hidden_dim, lstm_num_layers, embed_num, embed_dim, class_num, kernel_num, kernel_sizes):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.hidden_dim = lstm_hidden_dim\n",
        "        self.num_layers = lstm_num_layers\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Ci = 1\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "        self.C = C\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        # pretrained  embedding\n",
        "        self.embed.weight.data.copy_(vocab.vectors)\n",
        "        \n",
        "        # CNN\n",
        "        self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(D, self.hidden_dim, dropout=dropout, num_layers=self.num_layers)\n",
        "\n",
        "        # linear\n",
        "        L = len(Ks) * Co + self.hidden_dim\n",
        "        self.hidden2label1 = nn.Linear(L, L // 2)\n",
        "        self.hidden2label2 = nn.Linear(L // 2, C)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embed(x)\n",
        "\n",
        "        # CNN\n",
        "        cnn_x = embed\n",
        "        cnn_x = torch.transpose(cnn_x, 0, 1)\n",
        "        cnn_x = cnn_x.unsqueeze(1)\n",
        "        cnn_x = [F.relu(conv(cnn_x)).squeeze(3) for conv in self.convs1]  # [(N,Co,W), ...]*len(Ks)\n",
        "        cnn_x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in cnn_x]  # [(N,Co), ...]*len(Ks)\n",
        "        cnn_x = torch.cat(cnn_x, 1)\n",
        "        cnn_x = self.dropout(cnn_x)\n",
        "\n",
        "        # LSTM\n",
        "        lstm_x = embed.view(len(x), embed.size(1), -1)\n",
        "        lstm_out, _ = self.lstm(lstm_x)\n",
        "        lstm_out = torch.transpose(lstm_out, 0, 1)\n",
        "        lstm_out = torch.transpose(lstm_out, 1, 2)\n",
        "        lstm_out = F.max_pool1d(lstm_out, lstm_out.size(2)).squeeze(2)\n",
        "\n",
        "        # CNN and LSTM cat\n",
        "        cnn_x = torch.transpose(cnn_x, 0, 1)\n",
        "        lstm_out = torch.transpose(lstm_out, 0, 1)\n",
        "        cnn_lstm_out = torch.cat((cnn_x, lstm_out), 0)\n",
        "        cnn_lstm_out = torch.transpose(cnn_lstm_out, 0, 1)\n",
        "\n",
        "        # linear\n",
        "        cnn_lstm_out = self.hidden2label1(F.tanh(cnn_lstm_out))\n",
        "        cnn_lstm_out = self.hidden2label2(F.tanh(cnn_lstm_out))\n",
        "\n",
        "        # output\n",
        "        logit = cnn_lstm_out\n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XBXB28-_Kwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v4otZj_nQjP",
        "colab_type": "code",
        "outputId": "9280f9d1-e64f-4e91-e925-0348fa038cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv('train.tsv', sep='\\t')\n",
        "print(train.head())\n",
        "\n",
        "train = train.drop(columns=['PhraseId', 'SentenceId'])\n",
        "print(train)\n",
        "\n",
        "with open('train_drop.tsv','w') as f:\n",
        "  f.write(train.to_csv(sep='\\t', index=False))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PhraseId  ...  Sentiment\n",
            "0         1  ...          1\n",
            "1         2  ...          2\n",
            "2         3  ...          2\n",
            "3         4  ...          2\n",
            "4         5  ...          2\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "                                                   Phrase  Sentiment\n",
            "0       A series of escapades demonstrating the adage ...          1\n",
            "1       A series of escapades demonstrating the adage ...          2\n",
            "2                                                A series          2\n",
            "3                                                       A          2\n",
            "4                                                  series          2\n",
            "...                                                   ...        ...\n",
            "156055                                          Hearst 's          2\n",
            "156056                          forced avuncular chortles          1\n",
            "156057                                 avuncular chortles          3\n",
            "156058                                          avuncular          2\n",
            "156059                                           chortles          2\n",
            "\n",
            "[156060 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcZPyBX_Amgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f97ac143-242a-49f3-de7b-9ea1ac2be153"
      },
      "source": [
        "\n",
        "\n",
        "tokenize = lambda x: x.split()\n",
        "text = data.Field(sequential=True, tokenize=tokenize, lower=True, fix_length=200)\n",
        "#postprocessing=data.Pipeline(int)\n",
        "label = data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "train, test = data.TabularDataset.splits(path='.', train='train_drop.tsv', test='test.tsv', format='tsv', fields=[('text', text),('label', label)], filter_pred=lambda ex: ex.label in ['0', '1','2','3','4'])\n",
        "text.build_vocab(train, vectors=\"glove.6B.100d\")\n",
        "\n",
        "train, val = data.Dataset.split(train, split_ratio=0.8)\n",
        "\n",
        "train_iter, val_iter, test_iter = data.Iterator.splits((train, val, test), sort_key=lambda x: len(x.text), batch_size=16)#自动pad\n",
        "\n",
        "import torch.nn as nn\n",
        "vocab = text.vocab\n",
        "#embed = nn.Embedding(len(vocab), 100)\n",
        "#embed.weight.data.copy_(vocab.vectors)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n",
            "100%|█████████▉| 398405/400000 [00:16<00:00, 25242.35it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewFGErt0BodN",
        "colab_type": "code",
        "outputId": "4af7d384-cb99-4e0c-d916-71a5431ec38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "embed_dim = 100\n",
        "lstm_hidden_dim = 300\n",
        "lstm_num_layers = 1\n",
        "dropout = 0.75\n",
        "dropout_embed = 0.75\n",
        "\n",
        "kernel_num = 300\n",
        "kernel_sizes = 3,4,5\n",
        "\n",
        "embed_num = len(text.vocab)\n",
        "class_num = 5\n",
        "\n",
        "\n",
        "model = CNN_LSTM(lstm_hidden_dim, lstm_num_layers, embed_num, embed_dim, class_num, kernel_num, kernel_sizes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.75 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJw7Q_VyIzla",
        "colab_type": "code",
        "outputId": "14f6f20e-b470-49cf-ccbb-28dd35551221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "train_epoch(train_iter, val_iter, test_iter, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ## The 1 Epoch, All 200 Epoch ! ##\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hahaha tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "18.75\n",
            "\n",
            " Dev accuracy: Evaluation - loss: 0.170943 acc: 0.0064%(2/31212)\n",
            "hahaha tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "50.0\n",
            "\n",
            " Dev accuracy: Evaluation - loss: 0.110056 acc: 0.0032%(1/31212)\n",
            "hahaha tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "31.25\n",
            "\n",
            " Dev accuracy: Evaluation - loss: 0.107857 acc: 0.0160%(5/31212)\n",
            "hahaha tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
            "43.75\n",
            "\n",
            " Dev accuracy: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r0_gDxdLo6z",
        "colab_type": "code",
        "outputId": "e4bc71f4-0cde-4264-a383-a3e892bd83ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vars(train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': '2', 'text': ['guessed']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJDy4Fwibefe",
        "colab_type": "code",
        "outputId": "98a3010f-8514-48b7-855c-012c53893d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "vars(next(iter(train_iter)))['text']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[15799,    11,    19,  ...,    65,   484,  4375],\n",
              "        [    1,    44,   366,  ...,  3370,     3,     1],\n",
              "        [    1,  9442, 14140,  ...,    32,   484,     1],\n",
              "        ...,\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8szr0B6b8i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}